diff --git a/demo.ipynb b/demo.ipynb
index ebce2bc..a1ae1d1 100644
--- a/demo.ipynb
+++ b/demo.ipynb
@@ -295,7 +295,7 @@
     },
     {
       "cell_type": "code",
-      "execution_count": 5,
+      "execution_count": 2,
       "metadata": {
         "colab": {
           "base_uri": "https://localhost:8080/",
@@ -333,63 +333,27 @@
           "name": "stderr",
           "output_type": "stream",
           "text": [
-            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
-            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
-            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
-            "You will be able to reuse this secret in all of your notebooks.\n",
-            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
-            "  warnings.warn(\n",
-            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:982: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
+            "/home/ubuntu/miniconda3/envs/dla/lib/python3.10/site-packages/huggingface_hub/file_download.py:982: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
             "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
             "  warnings.warn(\n"
           ]
         },
-        {
-          "data": {
-            "application/vnd.jupyter.widget-view+json": {
-              "model_id": "cc2c2c20674749ec93bb52dda187cbd6",
-              "version_major": 2,
-              "version_minor": 0
-            },
-            "text/plain": [
-              "model_best.pth:   0%|          | 0.00/117M [00:00<?, ?B/s]"
-            ]
-          },
-          "metadata": {},
-          "output_type": "display_data"
-        },
-        {
-          "name": "stdout",
-          "output_type": "stream",
-          "text": [
-            "Downloaded: saved/conformer-rnn-t-small/model_best.pth\n"
-          ]
-        },
-        {
-          "data": {
-            "application/vnd.jupyter.widget-view+json": {
-              "model_id": "8f60169915644476ab40007fea383008",
-              "version_major": 2,
-              "version_minor": 0
-            },
-            "text/plain": [
-              "config.yaml: 0.00B [00:00, ?B/s]"
-            ]
-          },
-          "metadata": {},
-          "output_type": "display_data"
-        },
         {
           "name": "stdout",
           "output_type": "stream",
           "text": [
-            "Downloaded: saved/conformer-rnn-t-small/config.yaml\n",
-            "total 114264\n",
-            "drwxr-xr-x 3 root root      4096 Oct 18 20:49 .\n",
-            "drwxr-xr-x 3 root root      4096 Oct 18 20:49 ..\n",
-            "drwxr-xr-x 3 root root      4096 Oct 18 20:49 .cache\n",
-            "-rw-r--r-- 1 root root      4117 Oct 18 20:49 config.yaml\n",
-            "-rw-r--r-- 1 root root 116979327 Oct 18 20:49 model_best.pth\n"
+            "Downloaded: saved/conformer-rnn-t-small-other/model_best.pth\n",
+            "Downloaded: saved/conformer-rnn-t-small-other/config.yaml\n",
+            "total 222352\n",
+            "drwxrwxr-x 3 ubuntu ubuntu      4096 Oct 19 20:13 .\n",
+            "drwxrwxr-x 9 ubuntu ubuntu      4096 Oct 19 20:14 ..\n",
+            "drwxrwxr-x 3 ubuntu ubuntu      4096 Oct 19 20:13 .cache\n",
+            "-rw-rw-r-- 1 ubuntu ubuntu 110666434 Oct 17 02:26 checkpoint-epoch1.pth\n",
+            "-rw-rw-r-- 1 ubuntu ubuntu      4117 Oct 19 20:13 config.yaml\n",
+            "-rw-rw-r-- 1 ubuntu ubuntu        41 Oct 17 02:11 git_commit.txt\n",
+            "-rw-rw-r-- 1 ubuntu ubuntu       677 Oct 17 02:11 git_diff.patch\n",
+            "-rw-rw-r-- 1 ubuntu ubuntu      3762 Oct 17 02:26 info.log\n",
+            "-rw-rw-r-- 1 ubuntu ubuntu 116979327 Oct 19 20:13 model_best.pth\n"
           ]
         }
       ],
@@ -397,7 +361,7 @@
         "import os\n",
         "from huggingface_hub import hf_hub_download\n",
         "\n",
-        "os.makedirs(\"saved/conformer-rnn-t-small\", exist_ok=True)\n",
+        "os.makedirs(\"saved/conformer-rnn-t-small-other\", exist_ok=True)\n",
         "\n",
         "model_files = [\n",
         "    \"model_best.pth\",\n",
@@ -408,7 +372,7 @@
         "    file_path = hf_hub_download(\n",
         "        repo_id=\"Rerumnn/conformer-rnn-t\",\n",
         "        filename=file_name,\n",
-        "        local_dir=\"saved/conformer-rnn-t-small\",\n",
+        "        local_dir=\"saved/conformer-rnn-t-small-other\",\n",
         "        local_dir_use_symlinks=False\n",
         "    )\n",
         "    print(f\"Downloaded: {file_path}\")\n",
@@ -689,7 +653,8 @@
       "provenance": []
     },
     "kernelspec": {
-      "display_name": "Python 3",
+      "display_name": "dla",
+      "language": "python",
       "name": "python3"
     },
     "language_info": {
@@ -702,7 +667,7 @@
       "name": "python",
       "nbconvert_exporter": "python",
       "pygments_lexer": "ipython3",
-      "version": "3.10.4"
+      "version": "3.10.18"
     },
     "widgets": {
       "application/vnd.jupyter.widget-state+json": {
diff --git a/src/configs/metrics/inference.yaml b/src/configs/metrics/inference.yaml
index a571893..a1f2b33 100644
--- a/src/configs/metrics/inference.yaml
+++ b/src/configs/metrics/inference.yaml
@@ -3,7 +3,7 @@ inference:
     name: "CER_(Argmax)"
   - _target_: src.metrics.ArgmaxWERMetric
     name: "WER_(Argmax)"
-  # - _target_: src.metrics.BeamSearchCERMetric
-  #   name: "CER_(BeamSearch)"
-  # - _target_: src.metrics.BeamSearchWERMetric
-  #   name: "WER_(BeamSearch)"
+  - _target_: src.metrics.BeamSearchCERMetric
+    name: "CER_(BeamSearch)"
+  - _target_: src.metrics.BeamSearchWERMetric
+    name: "WER_(BeamSearch)"
diff --git a/src/model/conformer_rnn_t.py b/src/model/conformer_rnn_t.py
index 55a6bf9..b8d0170 100644
--- a/src/model/conformer_rnn_t.py
+++ b/src/model/conformer_rnn_t.py
@@ -111,7 +111,6 @@ class ConformerRNNT(nn.Module):
             for i in range(len(encodings)):
                 encoding = encodings[i]
                 length = x_lengths[i]
-

                 bos_token = torch.tensor(self.bos_idx, device=encoding.device)
                 g, h, c = self.prediction_network(bos_token.unsqueeze(0).unsqueeze(0), None, None)
@@ -135,18 +134,30 @@ class ConformerRNNT(nn.Module):
                         if len(a_hypos) == 0:
                             break

+                        next_hypos = {}
                         for hypo_key, hypo in a_hypos.items():
-                            logits = self.joint_network.infer(frame, hypo[2])
+                            print(hypo_key)
+                            logits = self.joint_network.infer(frame, hypo[1])
                             log_probs = F.log_softmax(logits, dim=-1).squeeze(0, 1)

                             # generate blank hypothesis
-                            blank_hyp = (
-                                hypo[0].logaddexp(log_probs[self.pad_idx]),
-                                hypo[1],
-                                hypo[2],
-                                hypo[3],
-                                hypo[4]
-                            )
+                            blank_hyp_prob = hypo[0] + log_probs[self.pad_idx]
+                            if hypo_key in b_hypos:
+                                blank_hyp = (
+                                    b_hypos[hypo_key][0].logaddexp(blank_hyp_prob),
+                                    hypo[1],
+                                    hypo[2],
+                                    hypo[3],
+                                    hypo[4]
+                                )
+                            else:
+                                blank_hyp = (
+                                    blank_hyp_prob,
+                                    hypo[1],
+                                    hypo[2],
+                                    hypo[3],
+                                    hypo[4]
+                                )

                             b_hypos[hypo_key] = blank_hyp

@@ -164,27 +175,26 @@ class ConformerRNNT(nn.Module):
                                     hypo[2],
                                     hypo[3],
                                 )
-                                logits = self.joint_network.infer(frame, new_g)
-                                log_probs = F.log_softmax(logits, dim=-1).squeeze(0, 1)

                                 new_hypo_key = hypo_key + f" {token_id}"
-                                new_hypo_prob = hypo[0].logaddexp(log_probs[token_id])
-                                new_hypo_last_token = token_id
+                                new_hypo_prob = hypo[0] + log_probs[token_id]

-                                a_hypos[new_hypo_key] = (
+                                next_hypos[new_hypo_key] = (
                                     new_hypo_prob,
-                                    new_hypo_last_token,
                                     new_g,
                                     new_h,
                                     new_c,
                                     hypo[4] + 1
                                 )

+                        a_hypos = next_hypos
+
                     b_hypos = dict(
                         sorted(b_hypos.items(), key=lambda x: x[1][0] / x[1][4], reverse=True)[
                             :beam_size
                         ]
                     )
+

                 result.append(
                     (
diff --git a/src/trainer/inferencer.py b/src/trainer/inferencer.py
index 2275143..ac7709e 100644
--- a/src/trainer/inferencer.py
+++ b/src/trainer/inferencer.py
@@ -134,8 +134,8 @@ class Inferencer(BaseTrainer):
         outputs = self.model.infer(**batch)
         batch.update(outputs)

-        # outputs_beam = self.model.infer_beam_search(beam_size=self.cfg_trainer.get('beam_size', 4) , **batch)
-        # batch.update(outputs_beam)
+        outputs_beam = self.model.infer_beam_search(beam_size=self.cfg_trainer.get('beam_size', 4) , **batch)
+        batch.update(outputs_beam)

         if metrics is not None:
             for met in self.metrics["inference"]:
@@ -144,13 +144,13 @@ class Inferencer(BaseTrainer):
         # Some saving logic. This is an example
         # Use if you need to save predictions on disk

-        batch_size = len(batch["result"])
+        batch_size = len(batch["result_beam"])
         current_id = batch_idx * batch_size

         for i in range(batch_size):
             # clone because of
             # https://github.com/pytorch/pytorch/issues/1995
-            pred_text = self.text_encoder.decode(batch["result"][i])
+            pred_text = self.text_encoder.decode(batch["result_beam"][i])

             if self.save_path is not None:
                 with open(
@@ -161,30 +161,30 @@ class Inferencer(BaseTrainer):

         return batch

-    def _log_batch(self, text, result, audio_path, **batch):
+    def _log_batch(self, text, result, result_beam, audio_path, **batch):
         argmax_texts = [self.text_encoder.decode(inds) for inds in result]
-        # beam_search_texts = [
-        #     self.text_encoder.decode(inds) for inds in result_beam
-        # ]
+        beam_search_texts = [
+            self.text_encoder.decode(inds) for inds in result_beam
+        ]

-        tuples = list(zip(argmax_texts, text, audio_path))
+        tuples = list(zip(argmax_texts, text, beam_search_texts, audio_path))

         rows = {}
-        for pred, target, audio_path in tuples:
+        for pred, target, beam_search_pred, audio_path in tuples:
             target = self.text_encoder.normalize_text(target)
             wer = calc_wer(target, pred) * 100
             cer = calc_cer(target, pred) * 100
-            # beam_search_wer = calc_wer(target, result_beam) * 100
-            # beam_search_cer = calc_cer(target, result_beam) * 100
+            beam_search_wer = calc_wer(target, beam_search_pred) * 100
+            beam_search_cer = calc_cer(target, beam_search_pred) * 100

             rows[Path(audio_path).name] = {
                 "target": target,
                 "argmax_predictions": pred,
-                # "beam_search_predictions": result_beam,
+                "beam_search_predictions": result_beam,
                 "argmax_wer": wer,
                 "argmax_cer": cer,
-                # "beam_search_wer": beam_search_wer,
-                # "beam_search_cer": beam_search_cer,
+                "beam_search_wer": beam_search_wer,
+                "beam_search_cer": beam_search_cer,
             }

         self.writer.add_table(
